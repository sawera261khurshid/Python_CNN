{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "history_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvokZsbuRsAi",
        "outputId": "b9cf4e1d-8b32-4832-a3fb-9d0e3658890f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root\n",
            "Github Repo exist.\n",
            "/root/Python_CNN\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (4.65.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (3.7.1)\n",
            "Requirement already satisfied: mnist==0.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.22.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 2)) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 2)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 2)) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 2)) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 2)) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 2)) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 2)) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 2)) (1.16.0)\n",
            "\n",
            "List of files\n",
            " cnn_keras.py\t\t\t    conva1.py\t\t   linear_biases.npy\n",
            " cnn.py\t\t\t\t    convaa1.py\t\t   linear_filters.npy\n",
            " CNN_Python_CIFAR.ipynb\t\t    conv_filters_3d.npy    max1a.py\n",
            " CNN_Python.ipynb\t\t    conv_filters.npy\t   maxpool.py\n",
            " CNN_Python_MNIST_and_CIFAR.ipynb   conv_new.py\t\t   maxpool_update.py\n",
            " cnn_scratch.py\t\t\t    conv.py\t\t   __pycache__\n",
            " CNN_Torch.ipynb\t\t    conv_update.py\t   python_cnn.py\n",
            " CNN_Torch_MNIST_and_CIFAR.py\t    data.csv\t\t   README.md\n",
            " cnn_torch.py\t\t\t    data.py\t\t   relu.py\n",
            " conv12aa1.py\t\t\t    exp_both.ipynb\t   requirements.txt\n",
            " conv12aa.py\t\t\t    exp_both.py\t\t   slowpool\n",
            " conv12a.py\t\t\t    exp_scratch.ipynb\t   soft_fc.py\n",
            " conv1a1.py\t\t\t    exp_shoaib.py\t   softmax.py\n",
            "'conv1aa1 (1).py'\t\t    exp_torch_both.ipynb   softmax_test.py\n",
            " conv1aa1a.py\t\t\t    exp_torch.ipynb\t   softmax_update.py\n",
            " conv1aa1.py\t\t\t    fc22a_update.py\t   solver.py\n",
            " conv1aaa1.py\t\t\t    fc22_update.py\t   submit.py\n",
            " conv1a.py\t\t\t    fc2_update.py\t   test2.py\n",
            " conv222_update.py\t\t    fca1.py\t\t   test.py\n",
            " conv22aa22_update.py\t\t    fcaa.py\t\t   untitled62.py\n",
            " conv22aa2_update.py\t\t    fcas1.py\t\t   utils.py\n",
            " conv22.py\t\t\t    fc.py\t\t   vis.py\n",
            " conv22_update.py\t\t    fc_update.py\t   weight_loader_2.py\n",
            " conv2aa_update.py\t\t    filters.npy\t\t   weight_loader.py\n",
            " conv2a_update.py\t\t    grad.py\t\t   weights\n",
            " conv2d.py\t\t\t    __init__.py\t\t   weights_fp16.npz\n",
            " conv2_update.py\t\t    LICENSE\t\t   yolov2tiny.py\n"
          ]
        }
      ],
      "source": [
        "%cd ~\n",
        "![ ! -d \"./Python_CNN\" ] && echo \"Github Repo DOES NOT exists.\"\n",
        "![ ! -d \"./Python_CNN\" ] && git clone https://github.com/sawera261khurshid/Python_CNN.git\n",
        "![ -d \"./Python_CNN\" ] && echo \"Github Repo exist.\"\n",
        "%cd Python_CNN\n",
        "%pip install -r requirements.txt\n",
        "!echo \n",
        "!echo List of files\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define settings for run\n",
        "\n",
        "debug=False\n",
        "\n",
        "shuffle_data=False\n",
        "\n",
        "run_train=True\n",
        "run_val=True\n",
        "\n",
        "load_saved_weights=False\n",
        "weight_file='weights/best_99.pkl'\n",
        "\n",
        "total_epoch=1\n",
        "training_acc_internal=1000"
      ],
      "metadata": {
        "id": "0DjRoCpNbQ3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "\n",
        "from logging import raiseExceptions\n",
        "import os\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import mnist\n",
        "import numpy as np\n",
        "from conv22aa2_update import Conv3x3_n_to_n_padding, Conv3x3_1_to_n_padding\n",
        "from maxpool import MaxPool2\n",
        "from softmax import Softmax\n",
        "from relu import Relu\n",
        "from softmax_test import Softmax_test\n",
        "from fc22a_update import FC\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from conv import Conv3x3\n",
        "\n",
        "# from logging import raiseExceptions\n",
        "# import os\n",
        "# import pickle\n",
        "# from tqdm import tqdm\n",
        "# import mnist\n",
        "# import numpy as np\n",
        "# from conv_update import Conv3x3, Conv3x3_n_to_n_padding, Conv3x3_1_to_n_padding\n",
        "# from maxpool_update import MaxPool2\n",
        "# from softmax_update import Softmax\n",
        "# from relu import Relu\n",
        "# from softmax_test import Softmax_test\n",
        "# from fc_update import FC"
      ],
      "metadata": {
        "id": "D9Pv4xIWRySB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Define settings for run\n",
        "\n",
        "# debug=False\n",
        "\n",
        "# shuffle_data=False\n",
        "\n",
        "# run_train=True\n",
        "# run_val=True\n",
        "\n",
        "# load_saved_weights=False\n",
        "# weight_file='weights/best_99.pkl'\n",
        "\n",
        "# total_epoch=10\n",
        "# training_acc_internal=1000"
      ],
      "metadata": {
        "id": "1mG2lp5mRyVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the network layers\n",
        "conv0   = Conv3x3_1_to_n_padding(output=8)  # 28x28x1   -> 28x28x8  (Convolution with 8 filters)\n",
        "pool0   = MaxPool2()                        # 28x28x8   -> 14x14x8  (MaxPooling 2x2)\n",
        "conv1   = Conv3x3_n_to_n_padding(output=16, inputch=8)  # 14x14x8   -> 14x14x16 (Convolution with 8 filters)\n",
        "pool1   = MaxPool2()                        # 14x14x16  -> 07x07x16 (MaxPooling 2x2)\n",
        "# conv2   = Conv3x3_n_to_n_padding(output=32, input=16)\n",
        "# conv3   = Conv3x3_n_to_n_padding(output=64, input=32)\n",
        "fc0     = FC(7 * 7 * 16, 7 * 7 * 16)        # 784       -> 784      (FC)\n",
        "fc1     = FC(7 * 7 * 16, 10)                # 784       -> 10       (FC)\n",
        "softmax = Softmax()                         # 14x14x8   -> 10       (Softmax)\n",
        "relu    = Relu()                            # 14x14x8   -> 10       (Softmax)"
      ],
      "metadata": {
        "id": "lO3Kw6JGRyXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv0   = Conv3x3_1_to_n_padding(output=8)  # 28x28x1   -> 28x28x8  (Convolution with 8 filters)\n",
        "weights = conv0.filters\n",
        "print(weights)\n",
        "print(weights.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ux6rmTPaFtz8",
        "outputId": "26c63046-8ab9-483b-a354-ed1b02bad3c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 8.76421854e-03 -2.19491217e-02 -5.17163463e-02]\n",
            "  [-1.07837737e-01 -7.47438073e-02  3.05433618e-03]\n",
            "  [-2.05582559e-01  2.49370024e-01 -7.28978291e-02]]\n",
            "\n",
            " [[-3.39461416e-02 -1.20964371e-01 -5.42755239e-02]\n",
            "  [ 1.33037329e-01 -4.19276394e-02  8.68640840e-02]\n",
            "  [-2.10059434e-02  9.61499885e-02 -1.16678663e-02]]\n",
            "\n",
            " [[-2.17765197e-02  1.94195420e-01  9.91955101e-02]\n",
            "  [ 1.06845982e-01 -1.76097322e-02 -1.24855906e-01]\n",
            "  [ 1.24380499e-01  1.91407382e-01 -6.45490959e-02]]\n",
            "\n",
            " [[-1.29245147e-01  1.04894124e-01  2.12606654e-01]\n",
            "  [ 9.20044035e-02 -8.46567452e-02 -1.05196141e-01]\n",
            "  [-1.79976374e-01 -1.47207707e-01  7.58061884e-03]]\n",
            "\n",
            " [[ 1.38613150e-01  1.16958795e-02 -1.17044784e-02]\n",
            "  [ 1.06800511e-01  1.67763963e-01 -1.21352501e-01]\n",
            "  [ 1.75869800e-02  1.10461324e-01 -1.73510984e-02]]\n",
            "\n",
            " [[-1.07559532e-01  5.56693077e-02  6.92823529e-02]\n",
            "  [ 1.19759493e-01  1.91018268e-01  1.53214976e-01]\n",
            "  [ 1.01159677e-01  1.12538032e-01  9.14930642e-05]]\n",
            "\n",
            " [[-9.99661982e-02  1.18720479e-01  1.47374094e-01]\n",
            "  [-2.94368062e-02  2.09083080e-01  9.44796205e-02]\n",
            "  [-1.58879444e-01  7.66472518e-02  2.90373955e-02]]\n",
            "\n",
            " [[ 9.47128311e-02 -1.27683103e-01  1.36678591e-01]\n",
            "  [-3.38279344e-02  8.40050578e-02 -1.72331914e-01]\n",
            "  [ 5.33681475e-02  3.36765826e-01 -5.67355603e-02]]]\n",
            "(8, 3, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv1  = Conv3x3_n_to_n_padding(output=16, inputch=8)  # 14x14x8   -> 14x14x16 (Convolution with 8 filters)\n",
        "weights_conv1 = conv1.filters\n",
        "print(weights)\n",
        "print(weights.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O878CnvGFt3B",
        "outputId": "b24aaf9c-ae77-4c5d-f99c-8ca541dc52bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 3.13439667e-02  1.22944742e-01 -9.95859727e-02]\n",
            "  [-5.07814400e-02 -8.26533064e-02  7.81429857e-02]\n",
            "  [ 1.93038434e-02  2.28372633e-01  1.50134847e-01]]\n",
            "\n",
            " [[ 1.21661477e-01 -3.99072692e-02 -1.13154091e-01]\n",
            "  [ 6.37363084e-03  1.33610979e-01  6.21094443e-02]\n",
            "  [-2.60762610e-02 -1.17974915e-01 -5.20447753e-02]]\n",
            "\n",
            " [[-2.12246209e-01  1.94701493e-01  7.72098452e-02]\n",
            "  [ 2.18349814e-01 -1.08544081e-01 -1.80429202e-02]\n",
            "  [ 3.07981111e-02 -1.82971656e-01  2.16257647e-02]]\n",
            "\n",
            " [[ 3.18273157e-02 -2.24405229e-01  1.18732534e-01]\n",
            "  [ 9.24406722e-02  7.15883151e-02  6.42885268e-03]\n",
            "  [ 8.40258002e-02 -1.17074504e-01 -1.33111656e-01]]\n",
            "\n",
            " [[-1.21933714e-01 -1.17211595e-01  5.97147197e-02]\n",
            "  [-3.78368143e-03 -8.08533356e-02 -9.21200588e-02]\n",
            "  [-1.05731510e-01 -3.19677964e-02 -4.00087237e-02]]\n",
            "\n",
            " [[-1.34399235e-01 -1.31620303e-01  2.74317771e-01]\n",
            "  [-6.33577555e-02  8.76044184e-02 -5.13922714e-05]\n",
            "  [-4.42624427e-02 -9.32039022e-02 -5.32314554e-02]]\n",
            "\n",
            " [[ 1.36276722e-01 -8.72253329e-02  5.73716164e-02]\n",
            "  [ 2.22502679e-01  1.20672077e-01 -7.77106558e-04]\n",
            "  [-3.35204341e-02 -9.38146189e-02  1.15516454e-01]]\n",
            "\n",
            " [[-1.57476529e-01 -1.95981964e-01  2.78235469e-02]\n",
            "  [-2.17275485e-01  1.94206312e-02  1.64677039e-01]\n",
            "  [-9.99979153e-02  6.19650036e-02  2.15969250e-01]]]\n",
            "(8, 3, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fc0 = FC(7 * 7 * 16, 7 * 7 * 16)\n",
        "# weights_fc0 = fc0.get_weights\n",
        "# print(weights_fc0)"
      ],
      "metadata": {
        "id": "oZ8XpCH8HSYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UuxwfswRHgGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2FeZExVkHgNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define FP16 copy of weights\n",
        "conv0_fp16 = Conv3x3_1_to_n_padding(output=8, dtype=np.float16)\n",
        "conv1_fp16 = Conv3x3_n_to_n_padding(output=16, inputch=8, dtype=np.float16)\n",
        "fc0_fp16 = FC(7 * 7 * 16, 7 * 7 * 16, dtype=np.float16)\n",
        "fc1_fp16 = FC(7 * 7 * 16, 10, dtype=np.float16)"
      ],
      "metadata": {
        "id": "EONVDUKaRyZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# conv0_fp16 = Conv3x3_1_to_n_padding(output=8, dtype=np.float16)\n",
        "# weights = conv0_fp16.filters\n",
        "# print(weights)"
      ],
      "metadata": {
        "id": "ZzzAvppDF_gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define scaling factor\n",
        "S = 128.0"
      ],
      "metadata": {
        "id": "zmceEoM-RygW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the network weights\n",
        "conv0.initialize_weights()\n",
        "conv1.initialize_weights()\n",
        "fc0.initialize_weights()\n",
        "fc1.initialize_weights()"
      ],
      "metadata": {
        "id": "Jqwa8LIgRyiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import sys\n",
        "\n",
        "# def forward(im, label, debug=False):\n",
        "#     im = (im / 255) - 0.5\n",
        "\n",
        "#     # Conv 0 with Pool\n",
        "#     out_conv0 = conv0.forward(im)\n",
        "#     out_pool0 = pool0.forward(out_conv0)\n",
        "#     sys.stdout.write(f\"Conv 0 output shape: {out_pool0.shape}\\n\")\n",
        "#     sys.stdout.flush()\n",
        "\n",
        "#     # Conv 1 with Pool\n",
        "#     out_conv1 = conv1.forward(out_pool0)\n",
        "#     out_pool1 = pool1.forward(out_conv1)\n",
        "#     sys.stdout.write(f\"Conv 1 output shape: {out_pool1.shape}\\n\")\n",
        "#     sys.stdout.flush()\n",
        "\n",
        "#     # Flatten the output for FC0\n",
        "#     out_pool1_flat = out_pool1.flatten()\n",
        "\n",
        "#     # FC0 and Relu\n",
        "#     out_fc0 = fc0.forward(out_pool1_flat)\n",
        "#     sys.stdout.write(f\"FC0 output shape: {out_fc0.shape}\\n\")\n",
        "#     sys.stdout.flush()\n",
        "\n",
        "#     # FC1 and SoftMax\n",
        "#     out_fc1 = fc1.forward(out_fc0)\n",
        "#     out_soft = softmax.forward(out_fc1)\n",
        "#     sys.stdout.write(f\"Softmax output shape: {out_soft.shape}\\n\")\n",
        "#     sys.stdout.flush()\n",
        "\n",
        "#     # Compute the loss\n",
        "#     loss = cal_loss(out_soft, label)\n",
        "\n",
        "#     # Compute the accuracy\n",
        "#     acc = compute_accuracy(out_soft, label)\n",
        "\n",
        "#     np.save('saved_weights.npy', model)\n",
        "\n",
        "\n",
        "#     return loss, acc, out_soft, weights"
      ],
      "metadata": {
        "id": "xw0K53lWRykv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import sys\n",
        "# import numpy as np\n",
        "\n",
        "# def forward(im, label, debug=False):\n",
        "#     im = (im / 255) - 0.5\n",
        "#     im = im.reshape((28, 28, 1))\n",
        "\n",
        "\n",
        "#     # Conv 0 with Pool\n",
        "#     out_conv0 = conv0.forward(im)\n",
        "#     out_pool0 = pool0.forward(out_conv0)\n",
        "#     sys.stdout.write(f\"Conv 0 output shape: {out_pool0.shape}\\n\")\n",
        "#     sys.stdout.flush()\n",
        "\n",
        "#     # Conv 1 with Pool\n",
        "#     out_conv1 = conv1.forward(out_pool0)\n",
        "#     out_pool1 = pool1.forward(out_conv1)\n",
        "#     sys.stdout.write(f\"Conv 1 output shape: {out_pool1.shape}\\n\")\n",
        "#     sys.stdout.flush()\n",
        "\n",
        "#     # Flatten the output for FC0\n",
        "#     out_pool1_flat = out_pool1.flatten()\n",
        "\n",
        "#     # FC0 and Relu\n",
        "#     out_fc0 = fc0.forward(out_pool1_flat)\n",
        "#     sys.stdout.write(f\"FC0 output shape: {out_fc0.shape}\\n\")\n",
        "#     sys.stdout.flush()\n",
        "\n",
        "#     # FC1 and SoftMax\n",
        "#     out_fc1 = fc1.forward(out_fc0)\n",
        "#     out_soft = softmax.forward(out_fc1)\n",
        "#     sys.stdout.write(f\"Softmax output shape: {out_soft.shape}\\n\")\n",
        "#     sys.stdout.flush()\n",
        "\n",
        "#    # After performing forward propagation\n",
        "# conv0_weights = conv0.filters\n",
        "# conv1_weights = conv1.filters\n",
        "# fc0_weights = fc0.weights\n",
        "# fc1_weights = fc1.weights\n",
        "\n",
        "# # Save the weights to a file\n",
        "# np.savez('weights.npz', conv0_weights=conv0_weights, conv1_weights=conv1_weights,\n",
        "#          fc0_weights=fc0_weights, fc1_weights=fc1_weights)"
      ],
      "metadata": {
        "id": "YL0mIXFayN4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jlTT-D011dp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Testing...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nX91DROHqj4Y",
        "outputId": "be7de3dc-a4d6-4bdf-8174-60f4202ee0bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a random 2D numpy array as the input\n",
        "input = np.random.rand(28, 28)\n",
        "\n",
        "# create an instance of the Conv3x3 class\n",
        "conv0 = Conv3x3(num_filters=8)\n",
        "pool0 = MaxPool2()\n",
        "\n",
        "# Forward pass\n",
        "out_conv0 = conv0.forward(input)\n",
        "out_pool0 = pool0.forward(out_conv0)\n",
        "\n",
        "# Print the output after each layer\n",
        "print(\"Conv1 output shape:\", out_conv0.shape)\n",
        "print(\"MaxPool1 output shape:\", out_pool0.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcrycjUVrZH4",
        "outputId": "23e2c8ec-8630-4d3d-9ac6-6feda3fff79e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv1 output shape: (26, 26, 8)\n",
            "MaxPool1 output shape: (13, 13, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a random 2D numpy array as the input\n",
        "input = np.random.rand(14, 14)\n",
        "\n",
        "# create an instance of the Conv3x3 class\n",
        "conv1 = Conv3x3(num_filters=16)\n",
        "pool1 = MaxPool2()\n",
        "\n",
        "# Forward pass\n",
        "out_conv1 = conv1.forward(input)\n",
        "out_pool1 = pool1.forward(out_conv1)\n",
        "\n",
        "# Print the output after each layer\n",
        "print(\"Conv1 output shape:\", out_conv1.shape)\n",
        "print(\"MaxPool1 output shape:\", out_pool1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCuqk3rEtFqO",
        "outputId": "21d8441c-2c57-4775-90af-93ac9036460a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv1 output shape: (12, 12, 16)\n",
            "MaxPool1 output shape: (6, 6, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2StUH1bNtFtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "unRxylzGtFvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Backward propagation using FP32 weights\n",
        "# def backward(label, out, loss=1, debug=False):\n",
        "#     # Compute the gradient of the Softmax layer\n",
        "#     gradient = out\n",
        "#     gradient[label] -= 1\n",
        "\n",
        "#     # Backpropagate through the softmax layer\n",
        "#     grad_softmax = softmax.backward(gradient)\n",
        "\n",
        "#     # Backpropagate through the fc1 layer\n",
        "#     grad_fc1 = fc1.backward(grad_softmax)\n",
        "\n",
        "#     # Backpropagate through the FC0 layer\n",
        "#     grad_fc0 = fc0.backward(grad_fc1)\n",
        "\n",
        "#     grad_pool1_flat = grad_pool1.flatten() \n",
        "       \n",
        "#     # Backpropagate through the MaxPool1 layer\n",
        "#     grad_pool1 = pool1.backward(grad_pool1_flat)\n",
        "\n",
        "#     # Backpropagate through the Conv1 layer\n",
        "#     grad_conv1 = conv1.backward(grad_pool1)\n",
        "\n",
        "#     # Backpropagate through the MaxPool0 layer\n",
        "#     grad_pool0 = pool0.backward(grad_conv1)\n",
        "\n",
        "#     # Backpropagate through the Conv0 layer\n",
        "#     grad_conv0 = conv0.backward(grad_pool0)"
      ],
      "metadata": {
        "id": "Mvqjyc68RynG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward propagation using FP16 weights\n",
        "def forward_fp16(im, label, debug=False):\n",
        "    im = (im / 255) - 0.5\n",
        "    im = im.reshape((28, 28, 1))\n",
        "    \n",
        "    print(\"Input shape:\", im.shape)\n",
        "    # print(\"Weights shape:\", self.weights.shape)\n",
        "\n",
        "    # Conv 0 with Pool\n",
        "    out_conv0 = conv0_fp16.forward(im)\n",
        "    out_pool0 = pool0.forward(out_conv0)\n",
        "\n",
        "    # Conv 1 with Pool\n",
        "    out_conv1 = conv1_fp16.forward(out_pool0)\n",
        "    out_pool1 = pool1.forward(out_conv1)\n",
        "\n",
        "    out_pool1_flat = out_pool1.flatten()\n",
        "    \n",
        "    # FC0 and Relu\n",
        "    out_fc0 = fc0_fp16.forward(out_pool1_flat)\n",
        "\n",
        "    # FC1 and SoftMax\n",
        "    out_fc1 = fc1_fp16.forward(out_fc0)\n",
        "    out_soft = softmax.forward(out_fc1)\n",
        "\n",
        "\n",
        "    # Reshape out_fc1\n",
        "    out_fc1_reshaped = out_fc1.reshape((1, -1))\n",
        "\n",
        "     # Calculate loss\n",
        "    loss_ = cal_loss(out_soft, label)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    acc_ = cal_accuracy(out_soft, label)\n",
        "\n",
        "    return loss_, acc_, out_soft\n",
        "\n",
        "    \n",
        "# After performing forward propagation\n",
        "conv0_weights = conv0_fp16.filters\n",
        "conv1_weights = conv1_fp16.filters\n",
        "fc0_weights = fc0_fp16.weights\n",
        "fc1_weights = fc1_fp16.weights\n",
        "pool0_weights = pool0.weights\n",
        "pool1_weights = pool1.weights\n",
        "# out_poolflat_weights = out_pool1_flat.weight\n",
        "\n",
        "\n",
        "print(\"conv0\" , conv0_fp16.filters)\n",
        "print(\"conv1\" , conv1_fp16.filters)\n",
        "print(\"fc0\" , fc0_fp16.weights)\n",
        "print(\"fc10\" , fc1_fp16.weights)\n",
        "print(\"pool0\" , pool0.weights)\n",
        "print(\"pool1\" , pool1.weights)\n",
        "# print(\"flat_pool1\" , out_pool1.weights)\n",
        "\n",
        "print(\"conv0\" , conv0_fp16.filters.shape)\n",
        "print(\"conv1\" , conv1_fp16.filters.shape)\n",
        "print(\"fc0\" , fc0_fp16.weights.shape)\n",
        "print(\"fc10\" , fc1_fp16.weights.shape)\n",
        "# print(\"pool0\" , pool0.weights.shape)\n",
        "# print(\"pool1\" , pool1.weights.shape)\n",
        "# # print(\"flat_pool1\" , out_pool1.weights.shape)\n",
        "\n",
        "# Save the weights to a file\n",
        "np.savez('weights_fp16.npz', conv0_weights=conv0_weights, conv1_weights=conv1_weights,\n",
        "         fc0_weights=fc0_weights, fc1_weights=fc1_weights)"
      ],
      "metadata": {
        "id": "VGr0TCO0Ryrg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50aacf83-e4a5-4b21-d4b8-19d7944f267e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv0 [[[ 0.1613   -0.02892   0.06433 ]\n",
            "  [-0.0711   -0.1395   -0.112   ]\n",
            "  [ 0.01545   0.1348    0.0941  ]]\n",
            "\n",
            " [[-0.1616   -0.0686   -0.0792  ]\n",
            "  [ 0.01692   0.074     0.0287  ]\n",
            "  [ 0.08704  -0.1393    0.0636  ]]\n",
            "\n",
            " [[ 0.06     -0.04977   0.097   ]\n",
            "  [ 0.03622  -0.2458    0.06903 ]\n",
            "  [ 0.01442   0.04132  -0.07385 ]]\n",
            "\n",
            " [[ 0.0519   -0.2006    0.1353  ]\n",
            "  [ 0.03424   0.1929    0.1405  ]\n",
            "  [-0.228     0.131     0.04965 ]]\n",
            "\n",
            " [[ 0.04517   0.01967   0.10614 ]\n",
            "  [-0.1854   -0.05838  -0.0786  ]\n",
            "  [-0.02339  -0.11926   0.0336  ]]\n",
            "\n",
            " [[-0.04675  -0.01074   0.0894  ]\n",
            "  [ 0.0716   -0.013535 -0.0889  ]\n",
            "  [-0.074    -0.07     -0.1558  ]]\n",
            "\n",
            " [[ 0.05725   0.03387  -0.0365  ]\n",
            "  [-0.1461   -0.014565  0.10657 ]\n",
            "  [ 0.1237   -0.1487   -0.02368 ]]\n",
            "\n",
            " [[-0.1853    0.07666  -0.11285 ]\n",
            "  [ 0.0959   -0.05344  -0.00989 ]\n",
            "  [-0.3098    0.0676    0.0879  ]]]\n",
            "conv1 [[[[-5.9143e-02  2.7661e-01  7.6111e-02 ...  4.3335e-02 -8.6914e-02\n",
            "    -1.8738e-01]\n",
            "   [-1.3696e-01 -4.0924e-02  1.9983e-01 ...  1.7004e-01 -9.0027e-03\n",
            "    -2.4756e-01]\n",
            "   [ 5.1636e-02 -6.4850e-03  1.6772e-01 ...  6.9031e-02  8.6182e-02\n",
            "    -4.6021e-02]]\n",
            "\n",
            "  [[-1.3818e-01  7.4951e-02 -3.0334e-02 ...  9.7595e-02 -4.9835e-02\n",
            "     2.0056e-01]\n",
            "   [-2.5742e-02 -1.3916e-01  1.7102e-01 ... -3.3203e-02 -1.9821e-02\n",
            "     2.9083e-02]\n",
            "   [-1.7810e-01 -9.1095e-03  3.0933e-01 ...  2.5146e-02  7.0068e-02\n",
            "    -1.9226e-02]]\n",
            "\n",
            "  [[ 1.9073e-02 -1.5979e-01 -4.5853e-03 ... -3.9032e-02 -1.4221e-01\n",
            "    -6.1951e-02]\n",
            "   [-9.7168e-02 -6.6406e-02  1.1035e-01 ... -4.5624e-03 -3.6774e-02\n",
            "    -1.1121e-01]\n",
            "   [-5.6763e-02  2.1713e-02  1.4270e-01 ... -3.1494e-02  2.8778e-02\n",
            "     1.5906e-01]]]\n",
            "\n",
            "\n",
            " [[[-7.8613e-02  1.7383e-01  2.0752e-02 ... -1.3574e-01 -8.8135e-02\n",
            "     8.2458e-02]\n",
            "   [ 8.9600e-02 -7.8796e-02  7.0679e-02 ... -7.3853e-02  1.7053e-01\n",
            "    -1.8445e-01]\n",
            "   [ 6.2378e-02  1.1743e-01  1.0016e-01 ...  8.4473e-02 -4.8035e-02\n",
            "     1.0681e-01]]\n",
            "\n",
            "  [[ 1.1163e-01 -5.8472e-02 -1.7688e-01 ...  6.8481e-02  4.5074e-02\n",
            "    -1.0162e-02]\n",
            "   [ 4.8981e-02  2.5009e-02  8.3923e-02 ...  1.7920e-01 -1.6296e-01\n",
            "    -1.4990e-01]\n",
            "   [-1.4282e-01  1.4819e-01  7.8308e-02 ...  1.3550e-01 -7.7820e-02\n",
            "    -8.4595e-02]]\n",
            "\n",
            "  [[-9.1370e-02  4.2084e-02 -5.3650e-02 ...  2.6123e-02  6.1646e-02\n",
            "     1.9580e-01]\n",
            "   [ 1.6663e-02 -4.4800e-02 -2.1439e-02 ... -6.2134e-02  1.6235e-01\n",
            "     6.7627e-02]\n",
            "   [ 2.0294e-02  7.2449e-02  1.5527e-01 ...  1.6199e-01  1.1450e-01\n",
            "     6.1096e-02]]]\n",
            "\n",
            "\n",
            " [[[ 1.8140e-01  3.1219e-02  1.6797e-01 ... -7.2510e-02  2.1698e-02\n",
            "     3.7384e-02]\n",
            "   [-1.2183e-01  1.7285e-01 -8.1787e-03 ... -1.3831e-01 -3.1860e-02\n",
            "    -2.4170e-01]\n",
            "   [-7.4951e-02  1.9189e-01  1.0095e-01 ...  1.0413e-01 -2.5195e-01\n",
            "    -5.7465e-02]]\n",
            "\n",
            "  [[-1.3708e-01 -5.6839e-03  4.2908e-02 ...  5.6030e-02 -1.7151e-02\n",
            "    -2.2720e-02]\n",
            "   [-6.2134e-02  5.7129e-02  7.8857e-02 ... -8.4412e-02  1.3049e-01\n",
            "     6.6833e-02]\n",
            "   [-2.2259e-03  7.2327e-02 -1.5100e-01 ...  1.7151e-02  7.5562e-02\n",
            "    -1.7529e-01]]\n",
            "\n",
            "  [[ 8.8623e-02 -1.7041e-01  1.6041e-03 ...  1.6626e-01 -1.8250e-01\n",
            "     1.2830e-01]\n",
            "   [-1.7981e-01  3.1787e-01  9.9609e-02 ...  1.0522e-01  9.5459e-02\n",
            "     4.2114e-02]\n",
            "   [-1.1218e-01  1.3538e-01  6.2683e-02 ... -2.0178e-01 -1.4331e-01\n",
            "     1.2457e-01]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ 9.7351e-02  1.6211e-01  1.5894e-01 ... -5.3955e-02 -2.0203e-02\n",
            "    -1.1945e-01]\n",
            "   [ 1.4587e-01  3.5309e-02 -1.2744e-01 ...  1.7786e-01  4.0894e-02\n",
            "    -2.6636e-01]\n",
            "   [ 1.5015e-01 -8.6365e-02 -9.7412e-02 ... -6.9336e-02  8.6548e-02\n",
            "    -2.8564e-01]]\n",
            "\n",
            "  [[-3.2883e-03  2.3108e-01 -7.1106e-02 ...  8.0719e-03  1.9287e-02\n",
            "     1.1633e-01]\n",
            "   [ 1.1328e-01 -4.6570e-02  3.0869e-02 ... -8.5144e-02  4.6997e-02\n",
            "    -1.3867e-01]\n",
            "   [ 2.0813e-02 -2.8503e-02 -2.8992e-02 ...  9.6069e-02  1.1664e-01\n",
            "    -7.4768e-04]]\n",
            "\n",
            "  [[ 1.8234e-02 -5.7831e-02  3.9749e-03 ... -1.7456e-01 -3.8300e-02\n",
            "    -2.4585e-01]\n",
            "   [ 1.4697e-01  9.9487e-02  1.1499e-01 ... -5.1056e-02  3.2593e-02\n",
            "     5.9624e-03]\n",
            "   [-1.4148e-01 -8.5327e-02  1.2009e-02 ... -2.0828e-03 -1.4636e-01\n",
            "    -3.1812e-01]]]\n",
            "\n",
            "\n",
            " [[[-2.1505e-04 -1.4587e-01 -8.6487e-02 ... -6.6284e-02 -2.9755e-02\n",
            "    -1.4795e-01]\n",
            "   [ 6.9946e-02 -1.0132e-01  1.2292e-01 ... -4.6722e-02  8.3130e-02\n",
            "    -1.4429e-01]\n",
            "   [ 4.2419e-02 -3.5278e-02  1.3838e-03 ...  1.2608e-03 -1.7212e-01\n",
            "     2.3353e-04]]\n",
            "\n",
            "  [[-1.7273e-01  1.0187e-01 -7.2193e-04 ...  6.3965e-02 -1.4000e-02\n",
            "     3.1036e-02]\n",
            "   [ 8.3771e-03 -6.8604e-02 -1.4734e-01 ...  9.3689e-03 -9.1553e-02\n",
            "     1.1200e-01]\n",
            "   [-2.4567e-02  1.1652e-01  1.8860e-02 ...  2.5342e-01 -7.0190e-02\n",
            "    -1.0248e-01]]\n",
            "\n",
            "  [[ 2.1790e-01 -1.8921e-01  3.4253e-01 ... -1.2964e-01  6.1188e-02\n",
            "    -7.9407e-02]\n",
            "   [ 4.1107e-02 -5.5359e-02 -6.7932e-02 ... -2.0044e-01 -8.5510e-02\n",
            "    -1.5601e-01]\n",
            "   [-1.4001e-01 -9.9487e-02 -9.4604e-02 ...  2.6382e-02 -4.7485e-02\n",
            "     3.0823e-03]]]\n",
            "\n",
            "\n",
            " [[[-1.2329e-01  4.0741e-02  5.4321e-02 ...  6.1035e-02 -1.2476e-01\n",
            "    -9.5459e-02]\n",
            "   [-5.0964e-02 -8.5632e-02 -4.7951e-03 ... -2.1631e-01 -1.4111e-01\n",
            "    -8.8806e-02]\n",
            "   [ 7.8857e-02  1.2054e-02 -1.8298e-01 ... -3.2227e-02  1.8628e-01\n",
            "     1.0651e-01]]\n",
            "\n",
            "  [[-1.1176e-01  1.9507e-01 -1.8604e-01 ...  4.0894e-02  3.1872e-03\n",
            "    -2.0471e-01]\n",
            "   [ 4.1809e-02 -2.5162e-02 -1.4111e-01 ...  9.6558e-02 -2.2068e-03\n",
            "    -1.6919e-01]\n",
            "   [ 8.9233e-02 -1.4441e-01  3.8357e-03 ... -1.0272e-01 -2.1118e-02\n",
            "     4.9858e-03]]\n",
            "\n",
            "  [[ 6.0333e-02  7.6599e-02  1.8311e-01 ...  5.2734e-02 -5.1331e-02\n",
            "    -2.0044e-01]\n",
            "   [ 1.0736e-01  6.9092e-02 -1.4856e-01 ...  4.1962e-02 -6.9397e-02\n",
            "     2.2034e-02]\n",
            "   [ 2.4200e-02 -2.1802e-01  1.1841e-01 ... -5.7526e-03  2.9709e-02\n",
            "     1.5710e-01]]]]\n",
            "fc0 [[ 3.04085872e-04 -7.66831999e-06 -2.02163379e-03 ...  2.25456385e-03\n",
            "   2.61423527e-04  1.33031723e-03]\n",
            " [ 1.38263311e-03 -2.90228403e-03  9.06185247e-04 ... -1.31536985e-03\n",
            "   9.18018573e-04  1.51715963e-03]\n",
            " [-2.66717398e-04 -8.11518461e-04  3.55778902e-05 ...  1.64794922e-03\n",
            "  -9.15527344e-04  1.16215926e-03]\n",
            " ...\n",
            " [ 9.08053655e-04  5.78588340e-04  1.24997506e-03 ...  9.21132625e-04\n",
            "   1.89084420e-03  8.44682945e-05]\n",
            " [-1.61431765e-03 -1.03463935e-04  5.36237436e-04 ...  1.79057213e-04\n",
            "  -3.66522348e-04  5.43088303e-04]\n",
            " [-2.46009062e-04 -2.17110780e-03  1.37765065e-03 ... -1.08835651e-04\n",
            "   1.44335689e-04 -5.46825177e-04]]\n",
            "fc10 [[-6.1657967e-04 -8.6881674e-04  1.2699049e-03 ...  7.4550085e-04\n",
            "  -5.7064757e-05  9.6301643e-05]\n",
            " [ 3.1439334e-03 -3.2853108e-04  4.4001365e-04 ...  6.8072882e-04\n",
            "   9.4433221e-05  2.3193359e-03]\n",
            " [ 1.3725125e-04 -4.1043028e-04  1.6217913e-03 ...  5.2720675e-04\n",
            "  -1.2537120e-03  1.2674137e-03]\n",
            " ...\n",
            " [-1.8833706e-03 -4.8859266e-04 -3.0112753e-04 ...  7.7165879e-04\n",
            "  -1.5570193e-03 -1.3527384e-03]\n",
            " [-6.1541185e-05  9.6223794e-04 -1.1428521e-03 ...  3.8676360e-04\n",
            "   5.0945673e-03  6.3962350e-04]\n",
            " [-8.7691325e-04 -1.6292650e-03  4.0264518e-04 ...  1.3514927e-04\n",
            "  -5.0789968e-04  9.8216778e-04]]\n",
            "pool0 None\n",
            "pool1 None\n",
            "conv0 (8, 3, 3)\n",
            "conv1 (16, 3, 3, 8)\n",
            "fc0 (784, 784)\n",
            "fc10 (784, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6FmtbhiFjAMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Backward propagation using FP16 weights\n",
        "# # Backward propagation using FP16 weights\n",
        "# def backward(label, out, loss=1, debug=False):\n",
        "#     # Compute the gradient of the Softmax layer\n",
        "#     gradient = out\n",
        "#     gradient[label] -= 1\n",
        "\n",
        "#     # Backpropagate through the softmax layer\n",
        "#     grad_softmax = softmax.backward(gradient)\n",
        "\n",
        "#     # Backpropagate through the fc1 layer\n",
        "#     grad_fc1 = fc1_fp16.backward(grad_softmax , lr)\n",
        "\n",
        "#     # Backpropagate through the FC0 layer\n",
        "#     grad_fc0 = fc0_fp16.backward(grad_fc1 , lr)\n",
        "\n",
        "#     # Reshape gradient_fc0 to match the dimensions before swapping axes\n",
        "#     gradient_fc0_reshape = grad_fc0.reshape((1, 64, 7, 7))\n",
        "\n",
        "#     # Swap axes to realign for flattening\n",
        "#     gradient_swap0 = np.swapaxes(gradient_fc0_reshape, 1, 2)\n",
        "#     gradient_swap1 = np.swapaxes(gradient_swap0, 2, 3)\n",
        "\n",
        "#     # # Backpropagate through the FC0 layer\n",
        "#     # grad_fc0 = fc0_fp16.backward(grad_fc1 , lr)\n",
        "    \n",
        "\n",
        "#     # # grad_pool1_flat = grad_pool1.flatten() \n",
        "#     # # Swap axes to realign for flattening\n",
        "#     # gradient_swap0 = grad_fc0\n",
        "#     # gradient_swap1 = np.swapaxes(gradient_swap0, 0, 2)\n",
        "       \n",
        "#     # Backpropagate through the MaxPool1 layer\n",
        "#     grad_pool1 = pool1.backward(gradient_swap1)\n",
        "\n",
        "#     # Backpropagate through the Conv1 layer\n",
        "#     grad_conv1 = conv1_fp16.backward(grad_pool1 , lr)\n",
        "\n",
        "#     # Backpropagate through the MaxPool0 layer\n",
        "#     grad_pool0 = pool0.backward(grad_conv1)\n",
        "\n",
        "#     # Backpropagate through the Conv0 layer\n",
        "#     grad_conv0 = conv0_fp16.backward(grad_pool0 , lr)\n",
        "\n",
        "\n",
        "# Backward propagation using FP16 weights\n",
        "def backward_fp16(label, out, loss=1, debug=False):\n",
        "    # Compute the gradient of the Softmax layer\n",
        "    gradient = out\n",
        "    gradient[label] -= 1\n",
        "\n",
        "    # Backpropagate through the Softmax layer\n",
        "    grad_softmax = softmax.backward(gradient)\n",
        "\n",
        "    # Backpropagate through the FC1 layer\n",
        "    grad_fc1 = fc1_fp16.backward(grad_softmax , lr)\n",
        "\n",
        "    # Backpropagate through the FC0 layer\n",
        "    grad_fc0 = fc0_fp16.backward(grad_fc1 , lr)\n",
        "\n",
        "    # Reshape the gradient to match the shape of the output of the pool1 layer\n",
        "    grad_fc0_reshaped = grad_fc0.reshape(1, 16, 7, 7)\n",
        "\n",
        "    # Backpropagate through the MaxPool1 layer\n",
        "    grad_pool1 = pool1.backward(grad_fc0_reshaped)\n",
        "\n",
        "    # Backpropagate through the Conv1 layer\n",
        "    grad_conv1 = conv1_fp16.backward(grad_pool1 , lr)\n",
        "\n",
        "    # Backpropagate through the MaxPool0 layer\n",
        "    grad_pool0 = pool0.backward(grad_conv1)\n",
        "\n",
        "    # Backpropagate through the Conv0 layer\n",
        "    grad_conv0 = conv0_fp16.backward(grad_pool0 , lr)\n",
        "\n",
        "    # Update the weights and biases of the layers\n",
        "    conv0_fp16.update_weights(lr)\n",
        "    conv1_fp16.update_weights(lr)\n",
        "    fc0_fp16.update_weights(lr)\n",
        "    fc1_fp16.update_weights(lr)\n",
        "\n",
        "    # Calculate the loss and accuracy\n",
        "    loss_ = cal_loss(out, label)\n",
        "    acc_ = cal_accuracy(out, label)\n",
        "\n",
        "    return loss_, acc_"
      ],
      "metadata": {
        "id": "CAIdVYiVRyt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Defining the network - Loss Function (Cross Entropy)\n",
        "# # Calculate cross-entropy loss and accuracy. np.log() is the natural log.\n",
        "# def cal_loss(out_soft, label):\n",
        "#   loss = -np.log(out_soft[label])\n",
        "#   acc = 1 if np.argmax(out_soft) == label else 0\n",
        "#   return out_soft, loss, acc\n",
        "\n",
        "def cal_accuracy(out_soft, label):\n",
        "    if out_soft.ndim > 1:\n",
        "        predicted_labels = np.argmax(out_soft, axis=1)\n",
        "    else:\n",
        "        predicted_labels = out_soft.round().astype(int)\n",
        "    accuracy = np.mean(predicted_labels == label)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "ZdHOlIBtl5FI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the network - Loss Function (Cross Entropy)\n",
        "# Calculate cross-entropy loss and accuracy. np.log() is the natural log.\n",
        "def cal_loss(out_soft, label):\n",
        "  loss = -np.log(out_soft[label])\n",
        "  acc = 1 if np.argmax(out_soft) == label else 0\n",
        "  return out_soft, loss, acc"
      ],
      "metadata": {
        "id": "kwpqR6pd_aD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the network - Training Function\n",
        "def train(im, label, debug=False, lr=.005):\n",
        "  pred = forward_fp16(im, label, debug)\n",
        "  out_soft, loss, acc = cal_loss(pred, label)\n",
        "  backward(label, out_soft, loss=loss, lr=0.005)\n",
        "  return loss, acc"
      ],
      "metadata": {
        "id": "2DnlSNosl5If"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the network - Validation Function\n",
        "def val(im, label):\n",
        "  pred = forward_fp16(im, label)\n",
        "  out_soft, loss, acc = cal_loss(pred, label)\n",
        "  return loss, acc"
      ],
      "metadata": {
        "id": "W4BoY0aLl5LW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function definitions to save and load weight files\n",
        "\n",
        "def save_weights(name,lr=0,max_acc=0):\n",
        "  print(f\"\\nSaving new weights ({name}).\")\n",
        "  weights = dict()\n",
        "  weights[\"conv0\"]        = conv0.filters\n",
        "  weights[\"conv1\"]        = conv1.filters\n",
        "  weights[\"fc0_weights\"]  = fc0.weights\n",
        "  weights[\"fc0_biases\" ]  = fc0.biases\n",
        "  weights[\"fc1_weights\"]  = fc1.weights\n",
        "  weights[\"fc1_biases\" ]  = fc1.biases\n",
        "  weights[\"lr\" ]          = lr\n",
        "  weights[\"max_acc\"]      = max_acc\n",
        "  weight_file = open(str(name), \"wb\")\n",
        "  pickle.dump(weights, weight_file)\n",
        "  weight_file.close()\n",
        "  \n",
        "def load_weights(name):\n",
        "  if os.path.isfile(name): \n",
        "    weight_file = open(str(name), \"rb\")\n",
        "    weights = pickle.load(weight_file)\n",
        "    conv0.filters  = weights[\"conv0\"]      \n",
        "    conv1.filters  = weights[\"conv1\"]      \n",
        "    fc0.weights    = weights[\"fc0_weights\"]\n",
        "    fc0.biases     = weights[\"fc0_biases\" ]\n",
        "    fc1.weights    = weights[\"fc1_weights\"]\n",
        "    fc1.biases     = weights[\"fc1_biases\" ]\n",
        "    lr             = weights[\"lr\" ]\n",
        "    max_acc        = weights[\"max_acc\"]\n",
        "    print(f\"\\nLoading weights from {name} file. LR restored to {lr}. Last Accuracy {max_acc}%\")\n",
        "    return lr, max_acc\n",
        "  else:\n",
        "    print(\"Weights file not found.\")\n",
        "    lr=0.005\n",
        "    max_acc=0\n",
        "    return lr, max_acc\n",
        "   "
      ],
      "metadata": {
        "id": "hIoiM2IYl5Ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the network - Adjust learning rate\n",
        "def adjust_lr(acc, lr=.005):\n",
        "  if   acc > 98: lr=0.00001\n",
        "  elif acc > 95: lr=0.0005\n",
        "  elif acc > 90: lr=0.001\n",
        "  elif acc > 80: lr=0.002\n",
        "  elif acc > 70: lr=0.003\n",
        "  elif acc > 60: lr=0.004\n",
        "  return lr"
      ],
      "metadata": {
        "id": "T-8ikNnFl5QU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Weights\n",
        "if load_saved_weights:\n",
        "    lr, max_acc = load_weights(weight_file)\n",
        "else:\n",
        "    lr, max_acc = 0.005, 0 \n",
        "\n",
        "if debug: save_weights(f'weights/debug.pkl', lr, max_acc)"
      ],
      "metadata": {
        "id": "Sxds3Jy-mN1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the training dataset - MNIST Dataset\n",
        "\n",
        "train_images = mnist.train_images()\n",
        "train_labels = mnist.train_labels()\n",
        "test_images = mnist.test_images()\n",
        "test_labels = mnist.test_labels()"
      ],
      "metadata": {
        "id": "W218ApSHmN43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle Data\n",
        "permutation = np.random.permutation(len(train_images))\n",
        "train_images = train_images[permutation]\n",
        "train_labels = train_labels[permutation]"
      ],
      "metadata": {
        "id": "AcKeMiMlmRdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Main function to run the training\n",
        " # please runnnnho jaa yarr \n",
        " # plzzz help ALLAH plzzzzz plzzzz\n",
        " # tere banda mushkilon ma hai girha \n",
        " # please ALLAH g mere ye project bohat acha ho jae AMEEN SUM AMEEN \n",
        "\n",
        "if run_train:\n",
        "  print(f'Training Initialized.')\n",
        "  print(f\"\\tTotal number of training   images: {len(train_labels)}\")\n",
        "  print(f\"\\tTotal number of validation images: {len(test_labels)}\")\n",
        "  print(f\"\\tTraining will run for {total_epoch} epochs.\")\n",
        "  print(f\"\\tResults will be logged after every {training_acc_internal} images.\")\n",
        "  # Training loop\n",
        "for epoch in range(3):\n",
        "    loss = 0\n",
        "    num_correct = 0\n",
        "    for i, (im, label) in enumerate(zip(mnist.train_images(), mnist.train_labels())):\n",
        "        # Forward propagation using FP32 weights\n",
        "        loss_, acc_, out_ = forward_fp16(im, label)\n",
        "\n",
        "        # Backward propagation using FP32 weights\n",
        "        backward(label, out_, loss_)\n",
        "\n",
        "        # Forward propagation using FP16 weights\n",
        "        loss_, acc_, out_ = forward_fp16(im, label)\n",
        "\n",
        "        # Scale the gradients\n",
        "        conv0_fp16.weights_grad /= S\n",
        "        conv1_fp16.weights_grad /= S\n",
        "        fc0_fp16.weights_grad /= S\n",
        "        fc1_fp16.weights_grad /= S\n",
        "\n",
        "        # Update the weights\n",
        "        conv0.weights -= conv0_fp16.weights_grad\n",
        "        conv1.weights -= conv1_fp16.weights_grad\n",
        "        fc0.weights -= fc0_fp16.weights_grad\n",
        "        fc1.weights -= fc1_fp16.weights_grad\n",
        "\n",
        "        loss += loss_\n",
        "        num_correct += acc_\n",
        "\n",
        "    print(f\"Epoch: {epoch}, Loss: {loss / len(mnist.train_images())}, Accuracy: {num_correct / len(mnist.train_images()) * 100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        },
        "id": "n8BhC7nYmRgZ",
        "outputId": "929b07dc-8879-4297-ce5a-395094e3f22b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Initialized.\n",
            "\tTotal number of training   images: 60000\n",
            "\tTotal number of validation images: 10000\n",
            "\tTraining will run for 1 epochs.\n",
            "\tResults will be logged after every 1000 images.\n",
            "Input shape: (28, 28, 1)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-725d5727deae>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m        \u001b[0;31m# Backward propagation using FP32 weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m        \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m        \u001b[0;31m# Forward propagation using FP16 weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-d3ce4fb527bf>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(label, out, loss, debug)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# Reshape the gradient to match the input shape of Conv1 layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mgradient_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_fc0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;31m# Backpropagate through the MaxPool1 layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    296\u001b[0m            [5, 6]])\n\u001b[1;32m    297\u001b[0m     \"\"\"\n\u001b[0;32m--> 298\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 784 into shape (1,64,7,7)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SYRMK81RmRtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uSlDlXcUmN7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(3):\n",
        "    loss = 0\n",
        "    num_correct = 0\n",
        "    for i, (im, label) in enumerate(zip(mnist.train_images(), mnist.train_labels())):\n",
        "        # Forward propagation using FP32 weights\n",
        "        loss_, acc_, out_ = forward(im, label)\n",
        "\n",
        "        # Backward propagation using FP32 weights\n",
        "        backward(label, out_, loss_)\n",
        "\n",
        "        # Forward propagation using FP16 weights\n",
        "        loss_, acc_, out_ = forward_fp16(im, label)\n",
        "\n",
        "        # Scale the gradients\n",
        "        conv0_fp16.weights_grad /= S\n",
        "        conv1_fp16.weights_grad /= S\n",
        "        fc0_fp16.weights_grad /= S\n",
        "        fc1_fp16.weights_grad /= S\n",
        "\n",
        "        # Update the weights\n",
        "        conv0.weights -= conv0_fp16.weights_grad\n",
        "        conv1.weights -= conv1_fp16.weights_grad\n",
        "        fc0.weights -= fc0_fp16.weights_grad\n",
        "        fc1.weights -= fc1_fp16.weights_grad\n",
        "\n",
        "        loss += loss_\n",
        "        num_correct += acc_\n",
        "\n",
        "    print(f\"Epoch: {epoch}, Loss: {loss / len(mnist.train_images())}, Accuracy: {num_correct / len(mnist.train_images()) * 100}%\")"
      ],
      "metadata": {
        "id": "Y0w6aJrdRywN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6uvkHd3lRyyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4pzSWoFIRy08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qfdZC-T8Ry3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1zhqPMJDRy5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PUENOaG3Ry-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oN4gZLVURzAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-0_C7_45RzCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V-u7d4diRzFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TzxpnKMmRzH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KAyaKQxyRzKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U4cQH941RzMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i54NRczCRzR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7b7v_m1HRzUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C94QrCVARzWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DyRruS5RRzZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9W5un_ZbRzbd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}