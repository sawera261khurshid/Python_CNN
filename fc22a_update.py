# -*- coding: utf-8 -*-
"""fc22a_update.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aSkAXIqSgqev5V5mczmtxJ-DBaNe9TEO
"""

import numpy as np

class FullyConnectedLayer:
    def __init__(self, input_size, output_size, activation=None, dtype=np.float32):
        self.input_size = input_size
        self.output_size = output_size
        self.activation = activation
        self.dtype = dtype

        # Initialize weights and biases
        self.weights = np.random.randn(output_size, input_size).astype(dtype) / np.sqrt(input_size)
        self.biases = np.zeros(output_size, dtype=dtype)

    def initialize_weights(self):
        self.weights = np.random.randn(self.output_size, self.input_size).astype(self.dtype) / np.sqrt(self.input_size)
        self.biases = np.zeros(self.output_size, dtype=self.dtype)

    def forward(self, input):
        '''
        Performs a forward pass of the FC layer using the given input.
        Returns a 1D numpy array with dimensions (output_size).
        - input is a 1D numpy array
        '''
        self.last_input = input
        output = np.dot(self.weights, input) + self.biases
        self.last_output = output
        if self.activation is not None:
            output = self.activation(output)
        return output

    def backprop(self, d_L_d_out, learn_rate):
        d_L_d_input = np.dot(self.weights.T, d_L_d_out)
        d_L_d_weights = np.outer(d_L_d_out, self.last_input)
        d_L_d_biases = d_L_d_out

        # Update weights and biases
        self.weights -= learn_rate * d_L_d_weights
        self.biases -= learn_rate * d_L_d_biases

        return d_L_d_input

    def get_weights(self):
      return self.filters

    def set_weights(self, weights):
      self.weights = weights